---
title: 'EST--24107: Tarea 3'
runningheader: 'Tarea 3'
author: |
  Carlos Lezama, Marco Medina, \
  Emiliano Ramírez y Santiago Villarreal
date: 'Lunes, 4 de octubre de 2021'
output:
    tufte::tufte_handout:
    citation_package: natbib
latex_engine: xelatex
link-citations: yes
---

```{r setup, include=FALSE}
library(tufte)
library(tidyverse)
library(copula)
library(Rlab)

knitr::opts_chunk$set(
  cache.extra = packageVersion('tufte'),
  cache = TRUE,
  fig.height = 8,
  fig.pos = '!h',
  fig.width = 8,
  message=FALSE,
  out.extra = '',
  out.width='75%',
  warning=FALSE
)

options(htmltools.dir.version = FALSE)
```

# Problema 1

```{r}
# Nuestra copula será una gaussiana, como vimos en clase,
# para poder otrogarle la estructura de dependencia que queremos.

copula_normal_4 <-
  normalCopula(c(0, 2 * (sin((
    -0.7 * pi
  ) / 6)), 2 * (sin((
    0.5 * pi
  ) / 6)), 2 * (sin((
    0.2 * pi
  ) / 6)), 2 * (sin((
    0.4 * pi
  ) / 6)), 0),
  dim = 4, dispstr = "un")

set.seed(170309)

U <- rCopula(5000, copula_normal_4)

pairs(U, pch = 16, cex = 0.5)

# Mostramos nuestra matriz de dependecia

round(cor(U, method = "spearman"), 2)

# Ahora generamos el vector X=(X1, X2, X3, X4) que se nos pide y
# hacemos los histogramas para ver si tienen el comportamiento deseado

X <- cbind(qnorm(U[, 1], mean = 4, sd = 3),
           qbern(U[, 2], prob = 0.6),
           qbeta(U[, 3], 2, 3),
           qgamma(U[, 4], 3, 2))

# Echamos un vistazo a como quedaron los datos de X
head(X)

# Visualizamos nuestros datos
pairs(X, pch = 16, cex = 0.5)

# Graficamos los histogramas y agregamos densidades con
# las distribuciones deseadas para ver la aproximación

par(mfrow = c(1, 1))
hist(
  X[, 1],
  prob = T,
  breaks = 50,
  main = "Histograma distr. Normal(4,9)",
  xlab = "Primera entrada vector X",
  ylab = "Densidad"
)

points(sort(X[, 1]), dnorm(sort(X[, 1]), 4, 3), type = "l", col = "blue")


hist(
  X[, 2],
  prob = T,
  breaks = 50,
  main = "Histograma distr. Bernoulli(0.6)",
  xlab = "Segunda entrada vector X",
  ylab = "Densidad"
)

points(sort(X[, 2]),
       dbern(sort(X[, 2]), prob = 0.6),
       type = "l",
       col = "blue")


hist(
  X[, 3],
  prob = T,
  main = "Histograma distr. Beta(2,3)",
  xlab = "Tercera entrada vector X",
  ylab = "Densidad"
)

points(sort(X[, 3]), dbeta(sort(X[, 3]), 2, 3), type = "l", col = "blue")


hist(
  X[, 4],
  prob = T,
  main = "Histograma distr. Gamma(3,2)",
  xlab = "Cuarta entrada vector X",
  ylab = "Densidad",
  ylim = c(0, 0.6)
)

points(sort(X[, 4]), dgamma(sort(X[, 4]), 3, 2), type = "l", col = "blue")

# Revisemos si nuestro vector cumple con
# la estructura de dependencia que queríamos imponer
cor(X, method = "spearman")

# No es exactamente igual a la estructura ideal que queremos,
# sin embargo se acerca mucho.
```

Observamos los histogramas de las distribuciones marginales para corroborar que tienen las distribuciones consideradas.

\newpage

# Problema 2

\newpage

# Problema 3

1. Mostrar que cuando $\theta \rightarrow \infty$, $C^{Fr}(u_1, u_2) \rightarrow min\{u_1, u_2\}$, donde $C^{Fr}$ es la cópula de Frank. 

\vspace{3mm}

Primero, supongamos que $u_2>u_1$ Sabemos que la cópula de Frank tiene la siguiente forma analítica para el caso bivariado: 

$$
\begin{aligned}
 C^{F r}\left(u_{1}, u_{2}\right)&=-\frac{1}{\theta} \log \left(1+\frac{\left(e^{-\theta u_{1}}-1\right)\left(e^{-\theta u_{2}}-1\right)}{e^{-\theta}-1}\right) \\
 &=-\frac{1}{\theta} \log \left(1+\frac{e^{-\theta u_1 - \theta u_2} -e^{\theta u1} -e^{\theta u_2} + 1}{e^{-\theta}-1}\right) \\
 \text{Cuando $\theta \rightarrow \infty$ entonces $e^{-\theta}-1 \approx -1$, por lo que } \\
 &\approx -\frac{1}{\theta} \log \left(1- e^{-\theta u_1 - \theta u_2} +e^{\theta u1} +e^{\theta u_2} - 1\right) \\
 &\approx -\frac{1}{\theta} \log \left(- e^{-\theta u_1 - \theta u_2} +e^{\theta u1} +e^{\theta u_2}\right) \\
 &\approx -\frac{1}{\theta} \log \left(e^{-\theta u_1}(-e^{-\theta u2} + 1 + e^{-\theta u_2}e^{\theta u1})\right) \\
 &\approx -\frac{1}{\theta} \log \left(e^{-\theta u_1}(-e^{-\theta u2} + 1 + e^{-\theta (u_2-u_1)})\right) \\
 \text{ya que $u_2 > u_1$, $-e^{-\theta u2} + 1 + e^{-\theta (u_2-u_1)} \rightarrow 1$ cuando $\theta \rightarrow \infty$  } \\
 &\approx -\frac{1}{\theta} \log \left(e^{-\theta u_1} \right) \\
 &\approx u_1 = min\{u_1,u_2\}
\end{aligned}
$$

\vspace{3mm}

Por tanto, cuando $\theta \rightarrow \infty$, $C^{Fr}(u_1, u_2) \rightarrow min\{u_1, u_2\}\; \blacksquare$

\newpage

# Problema 4

Probar que la cópula de Clayton converge a la cópula de comonoticidad cuando $\theta \to \infty$.

Notemos que la cópula de Clayton la podemos escribir como:

$$\exp[\ln(u_{1}^{-\theta} + u_{2}^{-\theta} - 1)/\theta]$$

Calculamos entonces el límite cuando $\theta \to \infty$ aplicando la regla de L'Hôpital:

$$\lim_{\theta\to\infty} \ln(u_{1}^{-\theta} + u_{2}^{-\theta} - 1)/\theta = \lim_{\theta\to\infty} \frac{1}{u_{1}^{-\theta} + u_{2}^{-\theta} - 1}\cdot[-u_{1}^{-\theta}\ln{u_{1}} + -u_{2}^{-\theta}\ln{u_{2}}] = \lim_{\theta\to\infty} -\frac{\sum_{i}u_{i}^{-\theta}\ln{u_{i}}}{\sum_{i}u_{i}^{-\theta} -1}$$

Sea $u_{m} = \min\{u_{1},u_{2}\}$, suponemos que $u_{m}\neq 0$. Dividimos y multiplicamos por $u_{m}^{\theta}$.

$$\implies \lim_{\theta\to\infty} -\frac{\sum_{i}u_{i}^{-\theta}\ln{u_{i}}}{\sum_{i}u_{i}^{-\theta} -1} = \lim_{\theta\to\infty} -\frac{\sum_{i}(u_{m}/u_{i})^{\theta}\ln{u_{i}}}{\sum_{i}(u_{m}/u_{i})^{\theta} -1}$$

Notemos que si $u_{i} \neq u_{m}$, entonces $u_{m}/u_{i} < 1$, por lo que $\lim_{\theta\to\infty} (u_{m}/u_{i})^{\theta} = 0$. Si $u_{i} = u_{m}$, entonces $u_{m}/u_{i} = 1$ y $\lim_{\theta\to\infty} (u_{m}/u_{i})^{\theta} = 1$. 

$$\implies \lim_{\theta\to\infty} -\frac{\sum_{i}(u_{m}/u_{i})^{\theta}\ln{u_{i}}}{\sum_{i}(u_{m}/u_{i})^{\theta} -1} = -\frac{\ln{u_{m}}}{-1} = \ln{u_{m}}$$

Por lo que si tomamos el límite completo:

$$ \lim_{\theta\to\infty} \exp\{\ln(u_{1}^{-\theta} + u_{2}^{-\theta} - 1)/\theta\} = \exp{\{\lim_{\theta\to\infty} \ln(u_{1}^{-\theta} + u_{2}^{-\theta} - 1)/\theta\ \}} = \exp{\{ \ln{u_{m}} \}} = u_{m}$$

Supongamos ahora que $u_{m} = 0$, en ese caso:

$$ \lim_{\theta\to\infty} [u_{1}^{-\theta} + u_{2}^{-\theta} - 1]^\frac{1}{\theta} = 0$$

Por lo tanto, la cópula de Clayton converge a la cópula de comonoticidad cuando $\theta \to \infty$.

\newpage

# Problema 5

\newpage

# Problema 6

#### Mostrar que la densidad conjunta correspondiente a la cópula Farlie-Gumbel-Morgenstern es no negativa.

\

Sea la densidad conjunta correspondiente a la cópula Farlie-Gumbel-Morgenstern:

$$\frac{\partial^{2}}{\partial u v} C(u,v) =  [1+\alpha(1-u)(1-v)] -\alpha v(1-u)-\alpha u(1-v) + \alpha u v$$

$$\implies \frac{\partial^{2}}{\partial u v} C(u,v) =  1 + \alpha(2u-1)(2v-1)$$
Basta con probar que $(2u-1)(2v-1) \geq -1$ para probar que $\frac{\partial^{2}}{\partial u v} C(u,v) \geq 0$. 

$$(2u-1)(2v-1) \geq -1 \iff \left[(2u-1)\geq\frac{-1}{(2v-1)} \land (2v-1) > 0 \right] \lor \left[(2u-1)\leq\frac{-1}{(2v-1)} \land (2v-1) < 0 \right] $$

Notemos que como $u$ y $v$ están entre 0 y 1. En el primer caso, la mayor cota inferior posible para $2u-1$ es cuando $v = 1$, entonces:

$$ (2u-1) \geq -1 \geq \frac{-1}{(2v-1)} $$

En el segundo caso, la menor cota superior posible para $2u-1$ es cuando $v = 0$, entonces:

$$(2u-1)\leq 0 \leq \frac{-1}{(2v-1)}$$

Por lo tanto $u$ cumple la desigualdad para todo valor de $v$. De manera análoga, por simetría, $v$ cumple la desigualdad para todo valor de $u$. Por lo tanto $(2u-1)(2v-1) \geq -1$ y $\frac{\partial^{2}}{\partial u v} C(u,v) \geq 0$.

#### Calcular el coeficiente de correlación de Spearman

\

Sabemos que si tenemos $C(u,v)$, entonces podemos calcular el coeficiente de correlación de Spearman como:

$$\rho = 12 \int_{0}^{1}\int_{0}^{1}C(u,v)dudv - 3 = 12 \int_{0}^{1}\int_{0}^{1}uvdC(u,v) - 3 = 3 - 6 \int_{0}^{1}\int_{0}^{1} \left(u \frac{\partial}{\partial u} C(u,v) +  v \frac{\partial}{\partial v} C(u,v)\right)dudv$$

$$\implies \rho = 3 - 6 \int_{0}^{1}\int_{0}^{1} uv+\alpha u(1-u)(1-v) - \alpha u^{2}v(1-v) + uv + \alpha(1-u)v(1-v) - \alpha u(1-u)v^{2} du dv$$

$$\implies \rho = 3 - 6 \int_{0}^{1} \frac{1}{2}v+  \frac{1}{6}\alpha (1-v) - \frac{1}{3} \alpha v(1-v) +  \frac{1}{2} v +  \frac{1}{2} \alpha v(1-v) -  \frac{1}{6}\alpha v^{2} dv$$


$$\implies \rho = 3 - 6 \left[\frac{1}{2}\cdot\frac{1}{2}+  \frac{1}{6}\cdot\frac{1}{2}\alpha - \frac{1}{3}\cdot\frac{1}{6} \alpha +  \frac{1}{2}\cdot\frac{1}{2} +  \frac{1}{2}\cdot\frac{1}{6} \alpha -  \frac{1}{6}\cdot\frac{1}{3}\alpha \right] = 3 - 6\left[\frac{1}{2} + \frac{1}{18} \alpha \right]$$

$$\therefore \rho = \frac{\alpha}{3}$$

Es decir, el coeficiente de correlación de Spearman de la cópula es función del parámetro $\alpha$, tal que $\rho(\alpha) \in (-\frac{1}{3},\frac{1}{3})$.

#### Calcular la tau de Kendall

\

Sabemos que si tenemos $C(u,v)$, entonces podemos calcular la tau de Kendall:

$$\tau = 4 \int_{0}^{1}\int_{0}^{1}C(u,v)dC(u,v) -1 = 1 - 4 \int_{0}^{1}\int_{0}^{1} \left(\frac{\partial}{\partial u} C(u,v) \cdot \frac{\partial}{\partial v} C(u,v)\right)dudv$$

$$\implies \tau = 1 - 4 \int_{0}^{1}\int_{0}^{1} uv + \alpha u(1-u)v(1-v) - \alpha u(1-u)v^{2} -\alpha u^{2}v(1-v)+ \alpha u(1-u)v(1-v) $$

$$ + \alpha^{2} u(1-u)^{2}v(1-v)^{2} - \alpha^{2}u(1-u)^{2} -\alpha^{2}u^{2}(1-u)v(1-v) + \alpha^{2}u^{2}(1-u)v^{2}(1-v)  dudv$$

OJO: notemos que los cuatro términos que incluyen a $\alpha^{2}$ se cancelan tras la integración.

$$\implies \tau = 1 - 4 \int_{0}^{1}\int_{0}^{1} uv + \alpha u(1-u)v(1-v) - \alpha u(1-u)v^{2} -\alpha u^{2}v(1-v)+ \alpha u(1-u)v(1-v) dudv$$
$$\implies \tau = 1 - 4 \int_{0}^{1} \frac{1}{2}v + \frac{1}{6}\alpha v(1-v) - \frac{1}{6}\alpha v^{2} -\frac{1}{3}\alpha v(1-v)+ \frac{1}{6}\alpha v(1-v) dv$$

$$\implies \tau = 1 - 4 \left[\frac{1}{2}\cdot\frac{1}{2} + \frac{1}{6}\cdot\frac{1}{6}\alpha - \frac{1}{6}\cdot\frac{1}{3}\alpha -\frac{1}{3}\cdot\frac{1}{6}\alpha + \frac{1}{6}\cdot\frac{1}{6}\alpha \right] = 1 -4 \left[\frac{1}{4} - \frac{1}{18}\alpha \right] = \frac{2}{9}\alpha$$

$$\therefore \tau = \frac{2}{9}\alpha$$

Es decir, la tau de Kendall de la cópula es función del parámetro $\alpha$, tal que $\tau(\alpha) \in (-\frac{2}{9},\frac{2}{9})$.

\newpage

# Problema 7

Sabemos $\tau = 0.2$.

1. Cópula normal (o cualquier elíptica): $\displaystyle \rho = \sin \left( \frac{\pi}{2}  \tau \right) =$ `r sin(pi * 0.2 / 2)`.
2. Cópula de Gumbel: $\displaystyle \alpha = \frac{1}{1 - \tau} =$ `r 1 / (1 - 0.2)`.
3. Cópula de Clayton: $\displaystyle \alpha = \frac{2 \tau}{1 - \tau} =$ `r (2 * 0.2) / (1 - 0.2)`.

\newpage

# Problema 8

Generación de cópulas:

```{r message=FALSE}
normCopula0.9 <- normalCopula(param = 0.9, dim = 2)
normCopula0.2 <- normalCopula(param = 0.2, dim = 2)
```

Visualización:

```{r echo=FALSE}
contour(normCopula0.9,
        pCopula,
        main = "CDF contour 0.9")
persp(normCopula0.9,
      pCopula,
      main = "CDF 0.9")
contour(normCopula0.9,
        dCopula,
        main = "Density contour 0.9")
persp(normCopula0.9,
      dCopula,
      main = "Density 0.9")

contour(normCopula0.2,
        pCopula,
        main = "CDF contour 0.2")
persp(normCopula0.2,
      pCopula,
      main = "CDF 0.2")
contour(normCopula0.2,
        dCopula,
        main = "Density contour 0.2")
persp(normCopula0.2,
      dCopula,
      main = "Density 0.2")
```

Nótese que con mayor coeficiente de correlación, más nos aproximamos a una relación lineal --- fácil de observar en las curvas de nivel de la función de probabilidad acumulada. Así pues, la dependencia lineal en la cópula gaussiana está directamente relacionada con su parámetro.

\newpage

# Problema 9

Simulamos 500 puntos cuya distribución son las cópulas del ejercicio 8 anterior.

```{r echo=FALSE}
normCopula0_9 <- normalCopula(param = 0.9, dim = 2)
rcop09<- rCopula(500, normCopula0_9)
pairs(rcop09, main = "Parámetro 0.9")
```

\

```{r echo=FALSE}
normCopula0_2 <- normalCopula(param = 0.2, dim = 2)
rcop02<- rCopula(500, normCopula0_2)
pairs(rcop02, main = "Parámetro 0.2")
```

Como podemos observar, existe una mayor dependencia entre las marginales cuando el parámetro de normalCopula es 0.9 que cuando es 0.2.

\newpage

\bibliography{}
